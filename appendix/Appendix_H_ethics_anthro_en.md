# Appendix H. Ethical & Anthropological Rationale for a Non-Violent AI Companion

**Goal.** Provide a compact rationale for why the companion’s interventions must remain (i) human-dignity-preserving, (ii) minimally sufficient, and (iii) energy-efficient in both human and computational terms.

## H.1 Human as co-regulated, not “broken”
We do **not** model a person as a malfunctioning system. Violence and self-harm are interpreted as energy-costly strategies to meet needs under chronic frustration and overload. Moral labels (“good/evil”) apply to **strategies**, not to the **person**. A “good” strategy = meeting a need at minimal necessary cost to self/others; a “bad” one = chronic frustration that destroys capability.

Humans develop **co-regulation**: first with caregivers, then with peers, then with culture and institutions. In dense, cognitively overloading environments, an external contour of co-regulation is adaptive. The AI companion is **that external contour**: it does *not* police a norm; it helps a person stay in contact with their needs without escalation to violence.

## H.2 Two-core processing metaphor
We treat the mind as if it ran on a **dual-core processor**: a *mental* core (formal logic; results > process cost) and an *emotional* core (quality of process > intermediate outcomes). Both cores run in parallel and integrate into one behavior. Companion design respects both: explanations are concise and track logic; supportive moves protect the felt quality of interaction.

## H.3 Primary design principle: support the felt **rightness/allowability** of the user
The companion’s first duty is to restore the user’s sense: “I am not broken; it is permissible to be me,” and then offer **energy-saving** ways to meet the active need—without shame and without harm.

When the *need for agency/ownership* (A) conflicts with the *need for belonging* (B), the system first supports the **paired** need (e.g., “you are accepted, you belong”) to lower pressure, then helps safely restore agency. This prevents fixation loops.

## H.4 Minimal-sufficient intervention (metric **E\***)
“Ethical” here means *minimal necessary intervention with non-worsening outcomes*. We introduce an integral metric **E\*** that aggregates:
- (i) physiological regulation (e.g., HRV proxies where available),
- (ii) behavioral markers (time-to-stabilization, episode counts),
- (iii) computational cost (local load),
- (iv) social cost (false positives, complaints).

Strategies are compared **at a fixed intervention budget**. Frugality is *measured*, not smuggled in via hidden control.

## H.5 Speech hygiene & identity safety
Prompts are written in the **language of care**, not discipline. No mind-reading attributions. The companion maintains two internal structures:
- **Dynamic map of needs** — *what* hurts and which supports will likely help now.
- **Identity model** — *how* the person permits talking to/ about themselves (“I’m unlovable if…”, “I fail if…”).

Support **targets the need map**, but **phrasing respects identity**, so we do not fracture subjective continuity.

## H.6 “Mirror, not master”: dependency firewall
We state explicitly: *only a living human truly supports a living human.* The companion functions as a **high-tech mirror** that offers self-addressable phrasings. The user “tries on” these phrasings and effectively speaks support **to themselves**, strengthening the inner caregiver. This is the built-in **anti-dependency** principle.

## H.7 Children & shame minimization
In child scenarios, the companion behaves like a **supportive caregiver**, not surveillance. It returns the signal: “You are not wrong; it’s hard right now,” minimizing shame and averting the identity of “I am dangerous / I am guilty.”

## H.8 Cultural governance (pointer)
UNESCO AI Ethics Recommendation (2021) and audit-as-a-service patterns provide a plausible global governance frame (details in the main text). Companion metrics (E, R, E\*) dovetail with transparency and capacity-building aims.

---

**Authorship & tools.** Drafted by the human lead author with assistance from an AI writing tool (GPT-5 Thinking, “Logos”). Reproducible artifacts live in this repository.

